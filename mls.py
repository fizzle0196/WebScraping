from bs4 import BeautifulSoup
import requests
import csv
import scrape

csv_file = open('mls_scrape.csv', 'a')
csv_writer = csv.writer(csv_file)

ROWS = [
        'mls_num',
        'num_pictures',
        'list_price',
        'price_perANDoriginal_list_price',
        'status',
        'cdom',
        'list_date',
        'dom',
        'address',
        'area',
        'city',
        'county',
        'restrictions',
        'subdivision',
        'taxes',
        'zoning1',
        'has_hoa',
        'hoa_transfer',
        'hoa_amenities',
        'pre_market',
        'school_dist',
        'elem',
        'jr_high',
        'sr_high',
        'total_sqfoot.text',
        'total_bedrooms.text',
        'total_bath_full.text',
        'total_bath_three_fourth.text',
        'total_bath_half.text',
        'total_family.text',
        'total_den.text',
        'total_formal_living_room.text',
        'total_kitchen_k.text',
        'total_kitchen_b.text',
        'total_kitchen_f.text',
        'total_kitchen_s.text',
        'total_laundry.text',
        'total_fireplace.text',
        'htype',
        'style',
        'year_built',
        'const_status',
        'effect_yr_built',
        'acres',
        'deck_patio',
        'frontage',
        'garage',
        'side',
        'carport',
        'back',
        'prkg_sp',
        'irregular',
        'fin_bsmt',
        'roof',
        'bsmt',
        'heating',
        'garage_park',
        'air_cond',
        'driveway',
        'floor',
        'water',
        'window_cov',
        'water_shares',
        'has_pool',
        'has_spa',
        'community_pool',
        'pool_feat',
        'master_level',
        'possession',
        'senior_comm',
        'exterior',
        'animals',
        'has_solar',
        'landscape',
        'lot_facts',
        'inclusions',
        'terms',
        'storage',
        'utilities',
        'zoning2',
        'remarks',
        'exterior_feat',
        'interior_feat',
        'amenities',
        'access_feat',
        'agt_remarks',
        'show_inst',
        'owner',
        'owner_type',
        'contact',
        'contact_type',
        'l_agent',
        'l_office',
        'l_broker',
        'bac',
        'dual_var',
        'list_type',
        'comm_type',
        'wthdrwn_dt',
        'off_mkt_dt',
        'exp_dt',
]

with open('test3.html') as html_file:
    soup = BeautifulSoup(html_file, 'lxml')

DATA = data.scrape_report(soup)

# csv_writer.writerow(ROWS)
csv_writer.writerow(DATA)
csv_file.close()